{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jc_a4BdGYOm2"
   },
   "source": [
    "# Plot Delineaion \n",
    " At first will put inplace all the requirede documents necessary foro the extractionof plot from satellie imagery \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szjYGNaWX-1K",
    "outputId": "08935490-f058-4953-d3be-1b9c0eea5f55"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/njr3/Mask_RCNN.git\n",
    "#%tensorflow_version 1.x\n",
    "#!pip install --upgrade h5py==2.10.0\n",
    "#!git clone https://github.com/pysource7/Mask_RCNN\n",
    "import sys\n",
    "#sys.path.append(\"/content/Mask_RCNN\")\n",
    "#from train_mask_rcnn_demo import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcC8__fDYALM",
    "outputId": "20661006-dbc0-4c18-f731-926aea3945c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'Mask_RCNN'\n",
      "C:\\Users\\Steven\\Downloads\\new_automation-20220128T083924Z-001\\new_automation\\Mask_RCNN\n"
     ]
    }
   ],
   "source": [
    "cd Mask_RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWiLvrtKYNHZ",
    "outputId": "cc192bbc-f850-458a-ce6c-49d61c8c305e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 31 16:24:17 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 511.09       Driver Version: 511.09       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 3000    WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   54C    P8     6W /  N/A |    583MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1580    C+G                                   N/A      |\n",
      "|    0   N/A  N/A      4636    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A      5424    C+G   ...kyb3d8bbwe\\Calculator.exe    N/A      |\n",
      "|    0   N/A  N/A     10136    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10412    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11732    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15920    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     16276    C+G   ...5.0.3.0\\GoogleDriveFS.exe    N/A      |\n",
      "|    0   N/A  N/A     18240    C+G   ...lack\\app-4.23.0\\slack.exe    N/A      |\n",
      "|    0   N/A  N/A     18732    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     19292    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     19612    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     22672    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cqDrqi4iY-Uo"
   },
   "outputs": [],
   "source": [
    "with open('mrcnn/model.py') as f:\n",
    "    model_file = f.read()\n",
    "\n",
    "with open('mrcnn/model.py', 'w') as f:\n",
    "    model_file = model_file.replace(\"self.keras_model = self.build(mode=mode, config=config)\",\n",
    "                                    \"self.keras_model = self.build(mode=mode, config=config)\\n        self.keras_model.metrics_tensors = []\")\n",
    "    f.write(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5KvM2MdtZLqz",
    "outputId": "84a33584-66d2-42c0-f999-fa8699e5470c"
   },
   "outputs": [],
   "source": [
    "#from osgeo import gdal\n",
    "import scipy\n",
    "import skimage\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import Polygon\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from affine import Affine\n",
    "from skimage.morphology import square, erosion, dilation\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import sys\n",
    "import skimage\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from os.path import isfile\n",
    "import geopandas\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import skimage.io as io\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from os.path import isfile\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "VLEIdauub1YZ"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18928/2773447407.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrasterio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#from osgeo import gdal, ogr, osr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\rasterio\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgdal_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrivers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_blacklisted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m from rasterio.dtypes import (\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "\n",
    "import rasterio\n",
    "import rasterio as rio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "#from osgeo import gdal, ogr, osr\n",
    "#import rasterio\n",
    "#from rasterio.plot import show\n",
    "#import rasterio as rio\n",
    "#from rasterio import windows\n",
    "#from rasterio import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18928/4294963926.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import Tcl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9exN-75VZbjD"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def interior_clean(path,out_path,eps,min_area=None):\n",
    "    shape=geopandas.read_file(path)\n",
    "    list_interiors = []\n",
    "    out=[]\n",
    "    r=[]\n",
    "    #eps = 10\n",
    "    for polygon in shape['geometry']:\n",
    "        for interior in polygon.interiors:\n",
    "            p = Polygon(interior)    \n",
    "            if p.area > eps:\n",
    "                list_interiors.append(interior)\n",
    "        new_polygon = Polygon(polygon.exterior.coords, holes=list_interiors)\n",
    "        out.append(new_polygon)\n",
    "    if min_area is not None:\n",
    "        for x in out:\n",
    "            if x.area>min_area:\n",
    "                r.append(x)\n",
    "    df3 = pd.DataFrame([ a for a in r],columns=['geometry'])\n",
    "    gdf = geopandas.GeoDataFrame(df3)\n",
    "    gdf.to_file(filename=out_path, driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLYIki0TcjFh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from os.path import isfile\n",
    "from tkinter import Tcl\n",
    "from osgeo import gdal\n",
    "\n",
    "def conversion(input_path ,path):\n",
    "  input= [f for f in listdir(input_path) if isfile(join(input_path, f)) and  f.endswith(\".tif\")]\n",
    "  inp=list(Tcl().call('lsort', '-dict',input))\n",
    "  for x in inp:\n",
    "    original_path=input_path+x\n",
    "    output_path= path+ x[:-4]+'.jpg'\n",
    "    #!gdal_translate -of JPEG -ot Byte  original_path output_path\n",
    "    os.system('gdal_translate -of JPEG -ot Byte {cd} {v} '.format(cd=original_path,v=output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1J_mqj-dckg1"
   },
   "outputs": [],
   "source": [
    "def filtering(path,save_path):\n",
    "    \"This function is to filter the image directly after it is out from the  deep learning  \"\n",
    "    nlyTIFF = [os.path.join( path, f) for f in listdir(path) if isfile(join(path, f)) and  f.endswith(\".jpg\")]\n",
    "    nlyTIFF=Tcl().call('lsort', '-dict',nlyTIFF)\n",
    "    if len(nlyTIFF)>=2:\n",
    "        for i in range(len(nlyTIFF)):\n",
    "            grayscale=io.imread(nlyTIFF[i],plugin='matplotlib')\n",
    "            median_filtered = scipy.ndimage.median_filter(grayscale, size=3)\n",
    "            threshold = skimage.filters.threshold_li(median_filtered)\n",
    "            predicted = np.uint8(median_filtered > threshold) * 255\n",
    "            io.imsave(os.path.join(save_path,\"predict_{}.tif\".format(int(i))), predicted )\n",
    "    elif len(nlyTIFF)==1:\n",
    "        grayscale=io.imread(nlyTIFF[0],plugin='matplotlib')\n",
    "        median_filtered = scipy.ndimage.median_filter(grayscale, size=3)\n",
    "        threshold = skimage.filters.threshold_li(grayscale)\n",
    "        predicted = np.uint8(median_filtered > threshold) * 255\n",
    "        io.imsave(os.path.join(save_path,\"predict.tif\"), predicted )\n",
    "    else:\n",
    "        print('No jpg file in the path given')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDOeFIGtcpU-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from os.path import isfile\n",
    "import rasterio\n",
    "import rasterio as rio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "import sys\n",
    "\n",
    "#inputArg = sys.argv\n",
    "#image_path = \"output/prediction/\"+inputArg[2] +'/'\n",
    "\n",
    "#out_path = \"output/merge/\"+inputArg[2] +'/'\n",
    "\n",
    "\n",
    "\n",
    "class Merge:\n",
    "    def merge(image_path,  out_path):\n",
    "        \"\"\"Merge a series of raster .\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    image_path : Str\n",
    "        Path to the series of raster.\n",
    "    save_path : Str\n",
    "        Path of to the merged raster.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A merge raster with it's metadata.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    This functions depends on \"rasterio\" and it's submodules.\n",
    "    \"\"\"\n",
    "        nlyTIFF = [os.path.join(image_path, f) for f in listdir(image_path) if isfile(join(image_path, f)) and  f.endswith(\".tif\")]\n",
    "    # List for the source files\n",
    "        src_files_to_mosaic = []\n",
    "        for fp in nlyTIFF:\n",
    "            src = rio.open(fp)\n",
    "            src_files_to_mosaic.append(src) \n",
    "        mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "        # Copy the metadata\n",
    "        out_meta = src.meta.copy()\n",
    "        # Update the metadata\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                \"height\": mosaic.shape[1],\n",
    "                 \"width\": mosaic.shape[2],\n",
    "                 \"transform\": out_trans,\n",
    "                 })\n",
    "        with rasterio.open(out_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(mosaic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luMqH7NFc4Oo"
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import skimage\n",
    "import numpy as np\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import Polygon\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Binary_mask_to_poly_geojson(imagepath,output_path, channel_scaling=None, reference_im=None,cr=None,\n",
    "                          output_type='geojson', min_area=27,\n",
    "                         bg_threshold=0, simplify=True,\n",
    "                         tolerance=15, **kwargs):\n",
    "    \"\"\"Get polygons from an image mask.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    pred_arr : :class:`numpy.ndarray`\n",
    "        A 2D array of integers. Multi-channel masks are not supported, and must\n",
    "        be simplified before passing to this function. Can also pass an image\n",
    "        file path here.\n",
    "    channel_scaling : :class:`list`-like, optional\n",
    "        If `pred_arr` is a 3D array, this argument defines how each channel\n",
    "        will be combined to generate a binary output. channel_scaling should\n",
    "        be a `list`-like of length equal to the number of channels in\n",
    "        `pred_arr`. The following operation will be performed to convert the\n",
    "        multi-channel prediction to a 2D output ::\n",
    "\n",
    "            sum(pred_arr[channel]*channel_scaling[channel])\n",
    "\n",
    "        If not provided, no scaling will be performend and channels will be\n",
    "        summed.\n",
    "    reference_im : str, optional\n",
    "        The path to a reference geotiff to use for georeferencing the polygons\n",
    "        in the mask. Required if saving to a GeoJSON (see the ``output_type``\n",
    "        argument), otherwise only required if ``do_transform=True``.\n",
    "    output_path : str, optional\n",
    "        Path to save the output file to. If not provided, no file is saved.\n",
    "    output_type : ``'csv'`` or ``'geojson'``, optional\n",
    "        If ``output_path`` is provided, this argument defines what type of file\n",
    "        will be generated - a CSV (``output_type='csv'``) or a geojson\n",
    "        (``output_type='geojson'``).\n",
    "    min_area : int, optional\n",
    "        The minimum area of a polygon to retain. Filtering is done AFTER\n",
    "        any coordinate transformation, and therefore will be in destination\n",
    "        units.\n",
    "    bg_threshold : int, optional\n",
    "        The cutoff in ``mask_arr`` that denotes background (non-object).\n",
    "        Defaults to ``0``.\n",
    "    simplify : bool, optional\n",
    "        If ``True``, will use the Douglas-Peucker algorithm to simplify edges,\n",
    "        saving memory and processing time later. Defaults to ``False``.\n",
    "    tolerance : float, optional\n",
    "        The tolerance value to use for simplification with the Douglas-Peucker\n",
    "        algorithm. Defaults to ``0.5``. Only has an effect if\n",
    "        ``simplify=True``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gdf : :class:`geopandas.GeoDataFrame`\n",
    "        A GeoDataFrame of polygons.\n",
    "\n",
    "    \"\"\"\n",
    "    mask_arr = skimage.io.imread(fname=imagepath)\n",
    "    if reference_im is None:\n",
    "        with rasterio.open(imagepath) as ref:\n",
    "            transform = ref.transform\n",
    "            crs = ref.crs\n",
    "            ref.close()\n",
    "    else:\n",
    "        with rasterio.open(reference_im) as ref:\n",
    "            transform = ref.transform\n",
    "            crs = ref.crs\n",
    "            ref.close()\n",
    "    mask = mask_arr > bg_threshold\n",
    "    mask = mask.astype('uint8')\n",
    "\n",
    "\n",
    "    polygon_generator = features.shapes(mask_arr,transform=transform,mask=mask)\n",
    "    polygons = []\n",
    "    values = []  # pixel values for the polygon in mask_arr\n",
    "    for polygon, value in polygon_generator:\n",
    "        p = shape(polygon).buffer(0.0)\n",
    "        if p.area >= min_area:\n",
    "            polygons.append(shape(polygon).buffer(0.0))\n",
    "            values.append(value)\n",
    "\n",
    "    polygon_gdf = gpd.GeoDataFrame({'geometry': polygons, 'value': values},\n",
    "                                   crs=crs.to_wkt())\n",
    "    if simplify:\n",
    "        polygon_gdf['geometry'] = polygon_gdf['geometry'].apply(\n",
    "            lambda x: x.simplify(tolerance=tolerance)\n",
    "        )\n",
    "    #changing the crs in case\n",
    "    if cr is not None:\n",
    "        polygon_gdf=polygon_gdf.to_crs(epsg=cr)\n",
    "    # save output files\n",
    "    if output_path is not None:\n",
    "        if output_type.lower() == 'geojson':\n",
    "            #if len(polygon_gdf) > 0:\n",
    "            polygon_gdf.to_file(output_path, driver='GeoJSON')\n",
    "            #else:\n",
    "                #save_empty_geojson(output_path, polygon_gdf.crs.to_epsg())\n",
    "        elif output_type.lower() == 'csv':\n",
    "            polygon_gdf.to_csv(output_path, index=False)\n",
    "        else:\n",
    "            polygon_gdf.to_file(output_path)\n",
    "    return polygon_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UwxQMgSc8kX"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "#rom osgeo import gdal, ogr, osr\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import os\n",
    "from itertools import product\n",
    "import rasterio as rio\n",
    "from rasterio import windows\n",
    "import sys\n",
    "\n",
    "tiles_width = 1024    #wedth of the image\n",
    "tiles_height = 1024   #heigh of the image\n",
    "output_filename = 'tile_{}-{}.tif'\n",
    "#input_filename='1.tif'\n",
    "#inputArg = sys.argv\n",
    "\n",
    "#out_path=\"/home/nteupe/extractBuildings/preprocessing/output/\"\n",
    "#in_path=\"/home/nteupe/extractBuildings/preprocessing/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#inputArg = sys.argv\n",
    "#ou_path=\"output/clip/\"\n",
    "#os.mkdir(ou_path+inputArg[1])\n",
    "#out_path=ou_path+inputArg[1] + '/'\n",
    "#in_path=\"input/\"= inputArg[1]+'/'\n",
    "#input_filename=inputArg[1]\n",
    "#tiles_width = 256\n",
    "#tiles_height = 256\n",
    "\n",
    "def get_tiles(ds, width = tiles_width, height = tiles_height):\n",
    "    nols, nrows = ds.meta['width'], ds.meta['height']\n",
    "    offsets = product(range(0, nols, width), range(0, nrows, height))\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "    for col_off, row_off in  offsets:\n",
    "        window =windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
    "        transform = windows.transform(window, ds.transform)\n",
    "        yield window, transform\n",
    "\n",
    "class Tiles:\n",
    "    def cut(in_path, input_filename, out_path,):\n",
    "        \"\"\" Slice the images into several images of equal dimensions.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        in_path : Str\n",
    "            Path to the image.\n",
    "        input_filename:str\n",
    "            Name of the image\n",
    "        save_path : Str\n",
    "            Path to sav the masked slice images .\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Several image of different dimension.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        This functions depends on \"rasterio\" with it's subfunctions.\n",
    "        \"\"\"\n",
    "        with rio.open(os.path.join(in_path, input_filename)) as inds:\n",
    "            output_filename = 'tile_{}-{}.tif'\n",
    "            tiles_width = 1024    #wedth of the image\n",
    "            tiles_height = 1024\n",
    "            tile_width, tile_height = tiles_width, tiles_height\n",
    "\n",
    "            meta = inds.meta.copy()\n",
    "\n",
    "            for window, transform in get_tiles(inds):\n",
    "                print(window)\n",
    "                meta['transform'] = transform\n",
    "                meta['width'], meta['height'] = window.width, window.height\n",
    "                outpath = os.path.join(out_path,output_filename.format(int(window.col_off), int(window.row_off)))\n",
    "                with rio.open(outpath, 'w', **meta) as outds:\n",
    "                    outds.write(inds.read(window=window))\n",
    "        print('ok') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzmAvzUOdVZV"
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from os.path import isfile\n",
    "from tkinter import *\n",
    "from tkinter import Tcl\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Transfer_info:\n",
    "    def Giveninfor(image_path, mask_path):\n",
    "        \"This function is to transfer geometric informationfrom one raster to another\"\n",
    "        output= [f for f in listdir(mask_path) if isfile(join(mask_path, f)) and  f.endswith(\".tif\")]\n",
    "        input= [f for f in listdir(image_path) if isfile(join(image_path, f)) and  f.endswith(\".tif\")]\n",
    "        inp=Tcl().call('lsort', '-dict',input)  \n",
    "        out=Tcl().call('lsort', '-dict',output)\n",
    "        print(len(inp))\n",
    "        print(len(out))\n",
    "        a=[]        #list the slide images\n",
    "        b=[]       # list for the mask\n",
    "        for file in inp:\n",
    "            a.append(gdal.Open(image_path + file, gdal.GA_ReadOnly))            \n",
    "        for file in out:\n",
    "            b.append(gdal.Open(mask_path + file, gdal.GA_Update))\n",
    "        for i in range(len(a)):\n",
    "            a[i].GetProjection()\n",
    "            a[i].GetGeoTransform()\n",
    "            b[i].SetProjection(a[i].GetProjection())          #setting the mask  projection\n",
    "            b[i].SetGeoTransform(a[i].GetGeoTransform())      #setting the mask trnsformatio\n",
    "            b[i]= None                          #saving the image link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5QMgT4zTdbES",
    "outputId": "31d2d5f3-b906-4dcb-df1b-eb24adaba494"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath('C:\\\\Users\\\\Steven\\\\Downloads\\\\new_automation-20220128T083924Z-001\\\\new_automation\\\\Mask_RCNN')\n",
    "print(\"VERS 0.2\")\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9y6L9IXdmuP",
    "outputId": "ea85f6a1-477e-4359-b6e2-723cdc81ff44"
   },
   "source": [
    "'''\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import skimage.io as io\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "\n",
    "class CustomConfig(Config):\n",
    "    def __init__(self, num_classes):\n",
    "\n",
    "        if num_classes > 1:\n",
    "            raise ValueError(\"{} classes were found. This is a DEMO version, and it only supports 1 class. Get the PRO version to\"\n",
    "                  \" continue the training.\".format(num_classes))\n",
    "\n",
    "        self.NUM_CLASSES = num_classes + 1\n",
    "        super().__init__()\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"object\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    #NUM_CLASSES = 1 + 1  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM =1024\n",
    "    IMAGE_MAX_DIM = 1024\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    # RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    # TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 30\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 15\n",
    "\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "NOTEBOOK PREFERENCES\n",
    "\"\"\"\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "\n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size * cols, size * rows))\n",
    "    return ax\n",
    "\n",
    "\n",
    "class CustomDataset(utils.Dataset):\n",
    "    \"\"\" Generates a COCO-like dataset, i.e. an image dataset annotated in the style of the COCO dataset.\n",
    "        See http://cocodataset.org/#home for more information.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_custom(self, annotation_json, images_dir, dataset_type=\"train\"):\n",
    "        \"\"\" Load the coco-like dataset from json\n",
    "        Args:\n",
    "            annotation_json: The path to the coco annotations json file\n",
    "            images_dir: The directory holding the images referred to by the json file\n",
    "        \"\"\"\n",
    "\n",
    "        # Load json from file\n",
    "        print(\"Annotation json path: \", annotation_json)\n",
    "        json_file = open(annotation_json)\n",
    "        coco_json = json.load(json_file)\n",
    "        json_file.close()\n",
    "\n",
    "\n",
    "        # Add the class names using the base method from utils.Dataset\n",
    "        source_name = \"coco_like\"\n",
    "        for category in coco_json['categories']:\n",
    "            class_id = category['id']\n",
    "\n",
    "            class_name = category['name']\n",
    "            if class_id < 1:\n",
    "                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(\n",
    "                    class_name))\n",
    "                return\n",
    "\n",
    "            self.add_class(source_name, class_id, class_name)\n",
    "\n",
    "        # Get all annotations\n",
    "        annotations = {}\n",
    "        #annotations= []\n",
    "        for annotation in coco_json['annotations']:\n",
    "            annotation['category_id']=1\n",
    "            image_id = annotation['image_id']\n",
    "            if image_id not in annotations:\n",
    "                annotations[image_id] = []\n",
    "            annotations[image_id].append(annotation)\n",
    "\n",
    "        # Get all images and add them to the dataset\n",
    "        seen_images = {}\n",
    "\n",
    "        # Split the dataset, if train, get 90%, else 10%\n",
    "        len_images = len(coco_json['images'])\n",
    "        if dataset_type == \"train\":\n",
    "            img_range = [int(len_images / 9), len_images]\n",
    "        else:\n",
    "            img_range = [0, int(len_images / 9)]\n",
    "\n",
    "        for i in range(img_range[0], img_range[1]):\n",
    "            image = coco_json['images'][i]\n",
    "            image_id = image['id']\n",
    "            if image_id in seen_images:\n",
    "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
    "            else:\n",
    "                seen_images[image_id] = image\n",
    "                try:\n",
    "                    image_file_name = image['file_name']\n",
    "                    image_width = image['width']\n",
    "                    image_height = image['height']\n",
    "                except KeyError as key:\n",
    "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
    "\n",
    "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n",
    "                image_annotations = annotations[image_id]\n",
    "                # Add the image using the base method from utils.Dataset\n",
    "                self.add_image(\n",
    "                    source=source_name,\n",
    "                    image_id=image_id,\n",
    "                    path=image_path,\n",
    "                    width=image_width,\n",
    "                    height=image_height,\n",
    "                    annotations=image_annotations\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "    def load_custom_val(self, annotation_json, images_dir, dataset_type=\"val\"):\n",
    "        \"\"\" Load the coco-like dataset from json\n",
    "        Args:\n",
    "            annotation_json: The path to the coco annotations json file\n",
    "            images_dir: The directory holding the images referred to by the json file\n",
    "        \"\"\"\n",
    "\n",
    "        # Load json from file\n",
    "        print(\"Annotation json path: \", annotation_json)\n",
    "        json_file = open(annotation_json)\n",
    "        coco_json = json.load(json_file)\n",
    "        json_file.close()\n",
    "\n",
    "\n",
    "        # Add the class names using the base method from utils.Dataset\n",
    "        source_name = \"coco_like\"\n",
    "        for category in coco_json['categories']:\n",
    "            class_id = category['id']\n",
    "\n",
    "            class_name = category['name']\n",
    "            if class_id < 1:\n",
    "                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(\n",
    "                    class_name))\n",
    "                return\n",
    "\n",
    "            self.add_class(source_name, class_id, class_name)\n",
    "\n",
    "        # Get all annotations\n",
    "        annotations = {}\n",
    "        #annotations= []\n",
    "        for annotation in coco_json['annotations']:\n",
    "            annotation['category_id']=1\n",
    "            image_id = annotation['image_id']\n",
    "            if image_id not in annotations:\n",
    "                annotations[image_id] = []\n",
    "            annotations[image_id].append(annotation)\n",
    "\n",
    "        # Get all images and add them to the dataset\n",
    "        seen_images = {}\n",
    "\n",
    "        # Split the dataset, if train, get 90%, else 10%\n",
    "        len_images = len(coco_json['images'])\n",
    "        if dataset_type == \"val\":\n",
    "            img_range = [int(len_images / 9), len_images]\n",
    "        else:\n",
    "            img_range = [0, int(len_images / 9)]\n",
    "\n",
    "        for i in range(img_range[0], img_range[1]):\n",
    "            image = coco_json['images'][i]\n",
    "            image_id = image['id']\n",
    "            if image_id in seen_images:\n",
    "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
    "            else:\n",
    "                seen_images[image_id] = image\n",
    "                try:\n",
    "                    image_file_name = image['file_name']\n",
    "                    image_width = image['width']\n",
    "                    image_height = image['height']\n",
    "                except KeyError as key:\n",
    "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
    "\n",
    "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n",
    "                image_annotations = annotations[image_id]\n",
    "                # Add the image using the base method from utils.Dataset\n",
    "                self.add_image(\n",
    "                    source=source_name,\n",
    "                    image_id=image_id,\n",
    "                    path=image_path,\n",
    "                    width=image_width,\n",
    "                    height=image_height,\n",
    "                    annotations=image_annotations\n",
    "                )\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\" Load instance masks for the given image.\n",
    "        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\n",
    "        Args:\n",
    "            image_id: The id of the image to load masks for\n",
    "        Returns:\n",
    "            masks: A bool array of shape [height, width, instance count] with\n",
    "                one mask per instance.\n",
    "            class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        image_info = self.image_info[image_id]\n",
    "        print(image_info)\n",
    "        annotations = image_info['annotations']\n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "\n",
    "        for annotation in annotations:\n",
    "            class_id = annotation['category_id']\n",
    "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
    "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
    "            for segmentation in annotation['segmentation']:\n",
    "                mask_draw.polygon(segmentation, fill=1)\n",
    "                bool_array = np.array(mask) > 0\n",
    "                instance_masks.append(bool_array)\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "        mask = np.dstack(instance_masks)\n",
    "        class_ids = np.array(class_ids, dtype=np.int32)\n",
    "        #print(\"Class_ids, \", class_ids)\n",
    "        return mask, class_ids\n",
    "\n",
    "    def count_classes(self):\n",
    "        class_ids = set()\n",
    "        for image_id in self.image_ids:\n",
    "            image_info = self.image_info[image_id]\n",
    "            annotations = image_info['annotations']\n",
    "\n",
    "            for annotation in annotations:\n",
    "                class_id = annotation['category_id']\n",
    "                class_ids.add(class_id)\n",
    "\n",
    "        class_number = len(class_ids)\n",
    "        return class_number\n",
    "\n",
    "def load_training_model(config):\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                              model_dir=MODEL_DIR)\n",
    "\n",
    "    # Which weights to start with?\n",
    "    init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "    if init_with == \"imagenet\":\n",
    "        model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    elif init_with == \"coco\":\n",
    "        # Load weights trained on MS COCO, but skip layers that\n",
    "        # are different due to the different number of classes\n",
    "        # See README for instructions to download the COCO weights\n",
    "        print(COCO_MODEL_PATH)\n",
    "        model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                           exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                                    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    elif init_with == \"last\":\n",
    "        # Load the last model you trained and continue training\n",
    "        model.load_weights(model.find_last(), by_name=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def display_image_samples(dataset_train):\n",
    "    # Load and display random samples\n",
    "    image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "\n",
    "    for image_id in image_ids:\n",
    "        image = dataset_train.load_image(image_id)\n",
    "        mask, class_ids = dataset_train.load_mask(image_id)\n",
    "        visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "def load_image_dataset(annotation_path, dataset_path, dataset_type):\n",
    "    dataset_train = CustomDataset()\n",
    "    dataset_train.load_custom(annotation_path, dataset_path, dataset_type)\n",
    "    dataset_train.prepare()\n",
    "    return dataset_train\n",
    "\n",
    "def load_image_dataset_val(annotation_path, dataset_path, dataset_type):\n",
    "    dataset_train = CustomDataset()\n",
    "    dataset_train.load_custom_val(annotation_path, dataset_path, dataset_type)\n",
    "    dataset_train.prepare()\n",
    "    return dataset_train\n",
    "\n",
    "\n",
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "def train_head(model, dataset_train, dataset_val, config):\n",
    "    model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=15,\n",
    "            layers='heads')\n",
    "\n",
    "\n",
    "def train_all_layers(model, dataset_train, dataset_val, config):\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE / 10,\n",
    "                epochs=15,\n",
    "                layers=\"all\")\n",
    "\n",
    "\n",
    "\"\"\" DETECTION TEST YOUR MODEL \"\"\"\n",
    "\n",
    "class InferenceConfig(CustomConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "def extract_images(my_zip, output_dir):\n",
    "    # Make directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    with zipfile.ZipFile(my_zip) as zip_file:\n",
    "        count = 0\n",
    "        for member in zip_file.namelist():\n",
    "            filename = os.path.basename(member)\n",
    "            # skip directories\n",
    "            if not filename:\n",
    "                continue\n",
    "            count += 1\n",
    "            # copy file (taken from zipfile's extract)\n",
    "            source = zip_file.open(member)\n",
    "            target = open(os.path.join(output_dir, filename), \"wb\")\n",
    "            with source, target:\n",
    "                shutil.copyfileobj(source, target)\n",
    "        print(\"Extracted: {} images\".format(count))\n",
    "\n",
    "\n",
    "def load_test_model(num_classes):\n",
    "    inference_config = InferenceConfig(num_classes)\n",
    "\n",
    "    # Recreate the model in inference mode\n",
    "    model = modellib.MaskRCNN(mode=\"inference\",\n",
    "                              config=inference_config,\n",
    "                              model_dir=MODEL_DIR)\n",
    "\n",
    "    # Get path to saved weights\n",
    "    # Either set a specific path or find last trained weights\n",
    "    # model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "    model_path = model.find_last()\n",
    "\n",
    "    # Load trained weights\n",
    "    print(\"Loading weights from \", model_path)\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "    return model, inference_config\n",
    "\n",
    "def load_inference_model(num_classes, model_path):\n",
    "    inference_config = InferenceConfig(num_classes)\n",
    "\n",
    "    # Recreate the model in inference mode\n",
    "    model = modellib.MaskRCNN(mode=\"inference\",\n",
    "                              config=inference_config,\n",
    "                              model_dir=model_path)\n",
    "\n",
    "    # Get path to saved weights\n",
    "    # Either set a specific path or find last trained weights\n",
    "    # model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "    #model_path = model.find_last()\n",
    "\n",
    "    # Load trained weights\n",
    "    print(\"Loading weights from \", model_path)\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "    return model, inference_config\n",
    "\n",
    "def test_random_image(test_model, dataset_val, inference_config):\n",
    "    image_id = random.choice(dataset_val.image_ids)\n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask = \\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "\n",
    "    log(\"original_image\", original_image)\n",
    "    # log(\"image_meta\", image_meta)\n",
    "    # log(\"gt_class_id\", gt_class_id)\n",
    "    # log(\"gt_bbox\", gt_bbox)\n",
    "    # log(\"gt_mask\", gt_mask)\n",
    "\n",
    "    # Model result\n",
    "    print(\"Trained model result\")\n",
    "    results = test_model.detect([original_image], verbose=1)\n",
    "    r = results[0]\n",
    "    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'],\n",
    "                                dataset_val.class_names, r['scores'], ax=get_ax(), show_bbox=False)\n",
    "\n",
    "    print(\"Annotation\")\n",
    "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id,\n",
    "                                dataset_val.class_names, figsize=(8, 8))\n",
    "\n",
    "\n",
    "\n",
    "def predict_results(class_number,path, MODEL_DIR ,Image_path, save_path):\n",
    "    config = CustomConfig(class_number)\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "    model.load_weights(path, by_name=True)\n",
    "    input= [os.path.join( Image_path, f) for f in listdir(Image_path) if isfile(join(Image_path, f)) and  f.endswith(\".jpg\")]\n",
    "    inp=Tcl().call('lsort', '-dict',input)\n",
    "    if len(inp)>=2:\n",
    "        for i in range(len(inp)):\n",
    "            image1 = mpimg.imread(inp[i])\n",
    "            results1 = model.detect([image1], verbose=1)\n",
    "            masks = results1[0]['masks']\n",
    "            masked_img=np.any(masks.astype(np.bool), axis=-1)\n",
    "            io.imsave(os.path.join(save_path,\"{}_mask.jpg\".format(i)), masked_img)\n",
    "    elif len(inp)==1:\n",
    "        image1 = mpimg.imread(inp[0])\n",
    "        results1 = model.detect([image1], verbose=1)\n",
    "        masks = results1[0]['masks']\n",
    "        masked_img=np.any(masks.astype(np.bool), axis=-1)\n",
    "        io.imsave(os.path.join(save_path,\"mask.jpg\"), masked_img)\n",
    "    else:\n",
    "        print( \"There is no files inside the folder\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62ZCT-AXeNgZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# General Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jCp3ogJZKTG"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "#from patchify import patchify, unpatchify\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4Y0k7SnKI9A",
    "outputId": "377a3792-b955-421c-dbec-8d81b0cf8c05"
   },
   "outputs": [],
   "source": [
    "class_number = 1\n",
    "\n",
    "config = CustomConfig(class_number)\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "model.load_weights(\"C:/Users/Steven/Downloads/new_automation-20220128T083924Z-001/new_automation/saved_model/mask_rcnn_object_0015.h5\", by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "-ReqzR0WUeiQ",
    "outputId": "7566df3b-62fa-4ad4-da88-7e7c827e3b42"
   },
   "outputs": [],
   "source": [
    "#Apply a trained model on large image\n",
    "import matplotlib.pyplot as plt\n",
    "test_image = cv2.imread('/content/drive/My Drive/plot_delineation/tile_8.tif') #BGR\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "print(test_image.shape)\n",
    "#Crop the image to be divisible by 1024\n",
    "patches_size = 1024\n",
    "test_image = cv2.resize(test_image, (test_image.shape[1]//1024 * patches_size,test_image.shape[0]//1024 * patches_size))\n",
    "print(test_image.shape)\n",
    "#This will split the image into small images of shape [3,3]\n",
    "#patches = patchify(test_image, (1024,1024, 3), step=1024)  #Step=1024 for 1024 patches means no overlap\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZwlROHsQpVu",
    "outputId": "a21afc45-1e84-44db-e2e2-cd52c3a6dbab"
   },
   "outputs": [],
   "source": [
    "image1 = mpimg.imread('/content/drive/My Drive/plot_delineation/Copy of tile_0_3072.jpg')\n",
    "\n",
    "def predict_image(tile_image):\n",
    "\n",
    "  results = model.detect([tile_image])\n",
    "  mask_generated = results[0]['masks']\n",
    "  masked_img=np.any(mask_generated.astype(np.bool), axis=-1)\n",
    "  #convert it to 4D\n",
    "  #masked_img = np.expand_dims(masked_img, axis=0)\n",
    " #masked_img = np.stack((masked_img,)*3, axis=-1)\n",
    "  return masked_img\n",
    "\n",
    "predict_image(image1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SlNO45MjF2do",
    "outputId": "5facf894-b144-41cd-9c08-d427582b4bef"
   },
   "outputs": [],
   "source": [
    "image1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xu8B6UqasRMy"
   },
   "outputs": [],
   "source": [
    "#res1 = predict_image(image1)\n",
    "\n",
    "#res1.shape\n",
    "#res2 = np.expand_dims(res1, axis=0)\n",
    "#print(res2.shape)\n",
    "#np.stack((res1,)*3, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKNSsd-hjFZ9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import matplotlib.pyplot as plt\n",
    "    PLOT_PROGRESS = True\n",
    "    # See end of file for the rest of the __main__.\n",
    "else:\n",
    "    PLOT_PROGRESS = False\n",
    "\n",
    "\n",
    "def _spline_window(window_size, power=2):\n",
    "    \"\"\"\n",
    "    Squared spline (power=2) window function:\n",
    "    https://www.wolframalpha.com/input/?i=y%3Dx**2,+y%3D-(x-2)**2+%2B2,+y%3D(x-4)**2,+from+y+%3D+0+to+2\n",
    "    \"\"\"\n",
    "    intersection = int(window_size/4)\n",
    "    wind_outer = (abs(2*(scipy.signal.triang(window_size))) ** power)/2\n",
    "    wind_outer[intersection:-intersection] = 0\n",
    "\n",
    "    wind_inner = 1 - (abs(2*(scipy.signal.triang(window_size) - 1)) ** power)/2\n",
    "    wind_inner[:intersection] = 0\n",
    "    wind_inner[-intersection:] = 0\n",
    "\n",
    "    wind = wind_inner + wind_outer\n",
    "    wind = wind / np.average(wind)\n",
    "    return wind\n",
    "\n",
    "\n",
    "cached_2d_windows = dict()\n",
    "def _window_2D(window_size, power=2):\n",
    "    \"\"\"\n",
    "    Make a 1D window function, then infer and return a 2D window function.\n",
    "    Done with an augmentation, and self multiplication with its transpose.\n",
    "    Could be generalized to more dimensions.\n",
    "    \"\"\"\n",
    "    # Memoization\n",
    "    global cached_2d_windows\n",
    "    key = \"{}_{}\".format(window_size, power)\n",
    "    if key in cached_2d_windows:\n",
    "        wind = cached_2d_windows[key]\n",
    "    else:\n",
    "        wind = _spline_window(window_size, power)\n",
    "        wind = np.expand_dims(np.expand_dims(wind, 1), 1)      #SREENI: Changed from 3, 3, to 1, 1 \n",
    "        wind = wind * wind.transpose(1, 0, 2)\n",
    "        if PLOT_PROGRESS:\n",
    "            # For demo purpose, let's look once at the window:\n",
    "            plt.imshow(wind[:, :, 0], cmap=\"viridis\")\n",
    "            plt.title(\"2D Windowing Function for a Smooth Blending of \"\n",
    "                      \"Overlapping Patches\")\n",
    "            plt.show()\n",
    "        cached_2d_windows[key] = wind\n",
    "    return wind\n",
    "\n",
    "\n",
    "def _pad_img(img, window_size, subdivisions):\n",
    "    \"\"\"\n",
    "    Add borders to img for a \"valid\" border pattern according to \"window_size\" and\n",
    "    \"subdivisions\".\n",
    "    Image is an np array of shape (x, y, nb_channels).\n",
    "    \"\"\"\n",
    "    aug = int(round(window_size * (1 - 1.0/subdivisions)))\n",
    "    more_borders = ((aug, aug), (aug, aug), (0, 0))\n",
    "    ret = np.pad(img, pad_width=more_borders, mode='reflect')\n",
    "    # gc.collect()\n",
    "\n",
    "    if PLOT_PROGRESS:\n",
    "        # For demo purpose, let's look once at the window:\n",
    "        plt.imshow(ret)\n",
    "        plt.title(\"Padded Image for Using Tiled Prediction Patches\\n\"\n",
    "                  \"(notice the reflection effect on the padded borders)\")\n",
    "        plt.show()\n",
    "    return ret\n",
    "\n",
    "\n",
    "def _unpad_img(padded_img, window_size, subdivisions):\n",
    "    \"\"\"\n",
    "    Undo what's done in the `_pad_img` function.\n",
    "    Image is an np array of shape (x, y, nb_channels).\n",
    "    \"\"\"\n",
    "    aug = int(round(window_size * (1 - 1.0/subdivisions)))\n",
    "    ret = padded_img[\n",
    "        aug:-aug,\n",
    "        aug:-aug,\n",
    "        :\n",
    "    ]\n",
    "    # gc.collect()\n",
    "    return ret\n",
    "\n",
    "\n",
    "def _rotate_mirror_do(im):\n",
    "    \"\"\"\n",
    "    Duplicate an np array (image) of shape (x, y, nb_channels) 8 times, in order\n",
    "    to have all the possible rotations and mirrors of that image that fits the\n",
    "    possible 90 degrees rotations.\n",
    "    It is the D_4 (D4) Dihedral group:\n",
    "    https://en.wikipedia.org/wiki/Dihedral_group\n",
    "    \"\"\"\n",
    "    mirrs = []\n",
    "    mirrs.append(np.array(im))\n",
    "    mirrs.append(np.rot90(np.array(im), axes=(0, 1), k=1))\n",
    "    mirrs.append(np.rot90(np.array(im), axes=(0, 1), k=2))\n",
    "    mirrs.append(np.rot90(np.array(im), axes=(0, 1), k=3))\n",
    "    im = np.array(im)[:, ::-1]\n",
    "    mirrs.append(np.array(im))\n",
    "    mirrs.append(np.rot90(np.array(im), axes=(0, 1), k=1))\n",
    "    mirrs.append(np.rot90(np.array(im), axes=(0, 1), k=2))\n",
    "    mirrs.append(np.rot90(np.array(im), axes=(0, 1), k=3))\n",
    "    return mirrs\n",
    "\n",
    "\n",
    "def _rotate_mirror_undo(im_mirrs):\n",
    "    \"\"\"\n",
    "    merges a list of 8 np arrays (images) of shape (x, y, nb_channels) generated\n",
    "    from the `_rotate_mirror_do` function. Each images might have changed and\n",
    "    merging them implies to rotated them back in order and average things out.\n",
    "    It is the D_4 (D4) Dihedral group:\n",
    "    https://en.wikipedia.org/wiki/Dihedral_group\n",
    "    \"\"\"\n",
    "    origs = []\n",
    "    origs.append(np.array(im_mirrs[0]))\n",
    "    origs.append(np.rot90(np.array(im_mirrs[1]), axes=(0, 1), k=3))\n",
    "    origs.append(np.rot90(np.array(im_mirrs[2]), axes=(0, 1), k=2))\n",
    "    origs.append(np.rot90(np.array(im_mirrs[3]), axes=(0, 1), k=1))\n",
    "    origs.append(np.array(im_mirrs[4])[:, ::-1])\n",
    "    origs.append(np.rot90(np.array(im_mirrs[5]), axes=(0, 1), k=3)[:, ::-1])\n",
    "    origs.append(np.rot90(np.array(im_mirrs[6]), axes=(0, 1), k=2)[:, ::-1])\n",
    "    origs.append(np.rot90(np.array(im_mirrs[7]), axes=(0, 1), k=1)[:, ::-1])\n",
    "    return np.mean(origs, axis=0)\n",
    "\n",
    "\n",
    "def _windowed_subdivs(padded_img, window_size, subdivisions, nb_classes, pred_func):\n",
    "    \"\"\"\n",
    "    Create tiled overlapping patches.\n",
    "    Returns:\n",
    "        5D numpy array of shape = (\n",
    "            nb_patches_along_X,\n",
    "            nb_patches_along_Y,\n",
    "            patches_resolution_along_X,\n",
    "            patches_resolution_along_Y,\n",
    "            nb_output_channels\n",
    "        )\n",
    "    Note:\n",
    "        patches_resolution_along_X == patches_resolution_along_Y == window_size\n",
    "    \"\"\"\n",
    "    WINDOW_SPLINE_2D = _window_2D(window_size=window_size, power=2)\n",
    "    \n",
    "    step = int(window_size/subdivisions)\n",
    "    padx_len = padded_img.shape[0]\n",
    "    pady_len = padded_img.shape[1]\n",
    "    subdivs = []\n",
    "    \n",
    "    for i in range(0, padx_len-window_size+1, step):\n",
    "        subdivs.append([])\n",
    "        for j in range(0, pady_len-window_size+1, step):            #SREENI: Changed padx to pady (Bug in original code)\n",
    "            patch = padded_img[i:i+window_size, j:j+window_size, :]\n",
    "            subdivs[-1].append(patch)\n",
    "   \n",
    "    # Here, `gc.collect()` clears RAM between operations.\n",
    "    # It should run faster if they are removed, if enough memory is available.\n",
    "    gc.collect()\n",
    "    subdivs = np.array(subdivs)\n",
    "    gc.collect()\n",
    "    a, b, c, d, e = subdivs.shape\n",
    "    subdivs = subdivs.reshape(a * b, c, d, e)\n",
    "    gc.collect()\n",
    "\n",
    "    subdivs = pred_func(subdivs)\n",
    "    gc.collect()\n",
    "\n",
    "    print(subdivs)\n",
    "    print(subdivs.shape)\n",
    "    subdivs = np.array([patch * WINDOW_SPLINE_2D for patch in subdivs])\n",
    "    gc.collect()\n",
    "\n",
    "    # Such 5D array:\n",
    "    subdivs = subdivs.reshape(a, b, c, d, nb_classes)\n",
    "    gc.collect()\n",
    "\n",
    "    return subdivs\n",
    "\n",
    "\n",
    "def _recreate_from_subdivs(subdivs, window_size, subdivisions, padded_out_shape):\n",
    "    \"\"\"\n",
    "    Merge tiled overlapping patches smoothly.\n",
    "    \"\"\"\n",
    "    step = int(window_size/subdivisions)\n",
    "    padx_len = padded_out_shape[0]\n",
    "    pady_len = padded_out_shape[1]\n",
    "\n",
    "    y = np.zeros(padded_out_shape)\n",
    "\n",
    "    a = 0\n",
    "    for i in range(0, padx_len-window_size+1, step):\n",
    "        b = 0\n",
    "        for j in range(0, pady_len-window_size+1, step):                #SREENI: Changed padx to pady (Bug in original code)\n",
    "            windowed_patch = subdivs[a, b]\n",
    "            y[i:i+window_size, j:j+window_size] = y[i:i+window_size, j:j+window_size] + windowed_patch\n",
    "            b += 1\n",
    "        a += 1\n",
    "    return y / (subdivisions ** 2)\n",
    "\n",
    "\n",
    "def predict_img_with_smooth_windowing(input_img, window_size, subdivisions, nb_classes, pred_func):\n",
    "    \"\"\"\n",
    "    Apply the `pred_func` function to square patches of the image, and overlap\n",
    "    the predictions to merge them smoothly.\n",
    "    See 6th, 7th and 8th idea here:\n",
    "    http://blog.kaggle.com/2017/05/09/dstl-satellite-imagery-competition-3rd-place-winners-interview-vladimir-sergey/\n",
    "    \"\"\"\n",
    "    pad = _pad_img(input_img, window_size, subdivisions)\n",
    "  \n",
    "\n",
    "    pads = _rotate_mirror_do(pad)\n",
    "   \n",
    "\n",
    "    # Note that the implementation could be more memory-efficient by merging\n",
    "    # the behavior of `_windowed_subdivs` and `_recreate_from_subdivs` into\n",
    "    # one loop doing in-place assignments to the new image matrix, rather than\n",
    "    # using a temporary 5D array.\n",
    "\n",
    "    # It would also be possible to allow different (and impure) window functions\n",
    "    # that might not tile well. Adding their weighting to another matrix could\n",
    "    # be done to later normalize the predictions correctly by dividing the whole\n",
    "    # reconstructed thing by this matrix of weightings - to normalize things\n",
    "    # back from an impure windowing function that would have badly weighted\n",
    "    # windows.\n",
    "\n",
    "    # For example, since the U-net of Kaggle's DSTL satellite imagery feature\n",
    "    # prediction challenge's 3rd place winners use a different window size for\n",
    "    # the input and output of the neural net's patches predictions, it would be\n",
    "    # possible to fake a full-size window which would in fact just have a narrow\n",
    "    # non-zero dommain. This may require to augment the `subdivisions` argument\n",
    "    # to 4 rather than 2.\n",
    "    res = []\n",
    "    for pad in tqdm(pads):\n",
    "        # For every rotation:\n",
    "        sd = _windowed_subdivs(pad, window_size, subdivisions, nb_classes, pred_func)\n",
    "        one_padded_result = _recreate_from_subdivs(\n",
    "            sd, window_size, subdivisions,\n",
    "            padded_out_shape=list(pad.shape[:-1])+[nb_classes])\n",
    "        \n",
    "        res.append(one_padded_result)\n",
    "\n",
    "    # Merge after rotations:\n",
    "    padded_results = _rotate_mirror_undo(res)\n",
    "\n",
    "    prd = _unpad_img(padded_results, window_size, subdivisions)\n",
    "\n",
    "    prd = prd[:input_img.shape[0], :input_img.shape[1], :]\n",
    "\n",
    "    if PLOT_PROGRESS:\n",
    "        plt.imshow(prd)\n",
    "        plt.title(\"Smoothly Merged Patches that were Tiled Tighter\")\n",
    "        plt.show()\n",
    "     \n",
    "    return prd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Z33YUbcFho67",
    "outputId": "40c9bb7e-eead-457b-e3a9-5a537f925f49"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from patchify import patchify, unpatchify\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "                  \n",
    "# size of patches\n",
    "patch_size = 1024\n",
    "\n",
    "# Number of classes \n",
    "n_classes = 3\n",
    "\n",
    "         \n",
    "###################################################################################\n",
    "#Predict using smooth blending\n",
    "\n",
    "# Use the algorithm. The `pred_func` is passed and will process all the image 8-fold by tiling small patches with overlap, called once with all those image as a batch outer dimension.\n",
    "# Note that model.predict(...) accepts a 4D tensor of shape (batch, x, y, nb_channels), such as a Keras model.\n",
    "predictions_smooth = predict_img_with_smooth_windowing(\n",
    "    test_image,\n",
    "    window_size=patch_size,\n",
    "    subdivisions=2,  # Minimal amount of overlap for windowing. Must be an even number.\n",
    "    nb_classes=n_classes,\n",
    "    pred_func=(\n",
    "        lambda img_batch_subdiv: predict_image((img_batch_subdiv))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "Wh0biE2q6HH_",
    "outputId": "727e2a66-cecf-437f-b5ec-d38b7d503465"
   },
   "outputs": [],
   "source": [
    "\n",
    "pad = _pad_img(test_image,  patch_size,  2)\n",
    "\n",
    "pads = _rotate_mirror_do(pad)\n",
    "\n",
    "pads[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXa5rjeR7HDL"
   },
   "outputs": [],
   "source": [
    "\n",
    "res = []\n",
    "for pad in tqdm(pads):\n",
    "    # For every rotation:\n",
    "    sd = _windowed_subdivs(pad, window_size, subdivisions, nb_classes, pred_func)\n",
    "    one_padded_result = _recreate_from_subdivs(\n",
    "        sd, window_size, subdivisions,\n",
    "        padded_out_shape=list(pad.shape[:-1])+[nb_classes])\n",
    "    \n",
    "    res.append(one_padded_result)\n",
    "\n",
    "# Merge after rotations:\n",
    "padded_results = _rotate_mirror_undo(res)\n",
    "\n",
    "prd = _unpad_img(padded_results, window_size, subdivisions)\n",
    "\n",
    "prd = prd[:input_img.shape[0], :input_img.shape[1], :]\n",
    "\n",
    "if PLOT_PROGRESS:\n",
    "    plt.imshow(prd)\n",
    "    plt.title(\"Smoothly Merged Patches that were Tiled Tighter\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgLu40xFan3F"
   },
   "outputs": [],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uH0msCc9UaR",
    "outputId": "65ce1877-0e9c-41dc-806b-1c4ca97020d3"
   },
   "outputs": [],
   "source": [
    "#_windowed_subdivs(pads[0], patch_size, 2, 1, model)\n",
    "\n",
    "padded_img = pads[0]\n",
    "window_size = patch_size\n",
    "subdivisions = 2\n",
    "nb_classes = 3\n",
    "WINDOW_SPLINE_2D = _window_2D(window_size, power=2)\n",
    "print(WINDOW_SPLINE_2D.shape)\n",
    "step = int(window_size/subdivisions)\n",
    "padx_len = padded_img.shape[0]\n",
    "pady_len = padded_img.shape[1]\n",
    "print((step,padx_len,pady_len))\n",
    "subdivs = []\n",
    "for i in range(0, padx_len-window_size+1, step):\n",
    "        subdivs.append([])\n",
    "        for j in range(0, pady_len-window_size+1, step):            #SREENI: Changed padx to pady (Bug in original code)\n",
    "            patch = padded_img[i:i+window_size, j:j+window_size, :]\n",
    "            subdivs[-1].append(patch)\n",
    "\n",
    "#gc.collect()\n",
    "subdivs = np.array(subdivs)\n",
    "#gc.collect()\n",
    "a, b, c, d, e = subdivs.shape\n",
    "subdivs = subdivs.reshape(a * b, c, d, e)\n",
    "#gc.collect()\n",
    "print(subdivs[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IYWjSzmSP_sP",
    "outputId": "062c9ef2-40e0-4270-e951-13ebd7ce3727"
   },
   "outputs": [],
   "source": [
    "\n",
    "subdivs = map(lambda subdivs : predict_image(subdivs), subdivs)\n",
    "subdivs\n",
    "gc.collect()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obuSwk1LKloO"
   },
   "outputs": [],
   "source": [
    "\n",
    "subdivs = np.array([patch * WINDOW_SPLINE_2D for patch in subdivs])\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSy3_5vB2IVK"
   },
   "outputs": [],
   "source": [
    "# Such 5D array:\n",
    "subdivs = subdivs.reshape(a, b, c, d, nb_classes)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgH4eWVw4ZDK"
   },
   "outputs": [],
   "source": [
    "subdivs1.reshape(9, 11, 1024, 1024, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "pzVkJ1GnOfmX",
    "outputId": "4178705c-44be-468f-d6b4-c30a9bce699d"
   },
   "outputs": [],
   "source": [
    "#subdivs1 = subdivs[0:2,:,:]\n",
    "#for patch in subdivs1:\n",
    " # patch = patch\n",
    "\n",
    "#patch.shape, WINDOW_SPLINE_2D.shape\n",
    "#patch * WINDOW_SPLINE_2D\n",
    "subdivs1 = subdivs1.reshape(2, 1, c, d, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jy39jAiiOUqs",
    "outputId": "9032b758-4d5f-4e13-bcb5-f289abfa74fe"
   },
   "outputs": [],
   "source": [
    "a, b, c, d\n",
    "subdivs1.shape,subdivs.shape,a, b, c, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnGgIUEWHrUg"
   },
   "outputs": [],
   "source": [
    "\n",
    "arr = np.array([[2,16,3,4],[1,30, 4, 16, 64],[17,3, 6, 9, 12]])\n",
    "#(map(lambda arr : sorted(arr), arr))\n",
    "\n",
    "# Sort each sublist\n",
    "#list(lambda arr: (sorted(i) for i in arr[i]))\n",
    "#[predict_image(arr) for i,arr in enumerate(subdivs)]\n",
    "\n",
    "#dd = list(map(lambda subdivs : predict_image(subdivs), subdivs))\n",
    "np.array(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbSmNhdsJOEq"
   },
   "outputs": [],
   "source": [
    "List = [[2,3,4],[1, 4, 16, 64],[3, 6, 9, 12]]\n",
    " \n",
    "# Sort each sublist\n",
    "sortList = lambda x: (sorted(i) for i in x)\n",
    "print((sortList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oy00TsqMHhlr"
   },
   "outputs": [],
   "source": [
    "list(lambda subdivs: (predict_image(i) for i in subdivs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwWx8RLmC2yg"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "subdivs = pred_func(subdivs)\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "subdivs = np.array([patch * WINDOW_SPLINE_2D for patch in subdivs])\n",
    "gc.collect()\n",
    "\n",
    "# Such 5D array:\n",
    "subdivs = subdivs.reshape(a, b, c, d, nb_classes)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKgd92ojxCTT"
   },
   "outputs": [],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xi4ZZkDxCU1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7Eg4IwZjrij"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "final_prediction = np.argmax(predictions_smooth, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_871dNJkFwN"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(221)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_image)\n",
    "plt.subplot(222)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(test_image)\n",
    "plt.subplot(223)\n",
    "plt.title('Prediction with smooth blending')\n",
    "plt.imshow(final_prediction)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcCnVM0SR3Pc"
   },
   "outputs": [],
   "source": [
    "io.imsave('/content/drive/My Drive/plot_delineation/prediction_test1.jpg',reconstructed_image)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Plot Delineation WorkflowV2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
